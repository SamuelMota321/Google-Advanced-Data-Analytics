{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fd85b2",
   "metadata": {},
   "source": [
    "#  New York City Taxi and Limousine Commission Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841624b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**This notebook has a goal apply de PACE strategy on 2017_Yellow_Taxi_Trip_Data dataset to build a predictive model for total amount of a taxi trip**\n",
    "\n",
    "---\n",
    "\n",
    "## **PACE: Plan**\n",
    "\n",
    "This stage is where i've the first contact with the dataset and when i start to plan what to do with the data to achieve my goals. Normally, I start making some questions to dataset. Let's get start  (Remenber, this first questions don't have high accuracy )\n",
    "\n",
    "### What are the data columns most relevant to your deliverable?\n",
    "\n",
    "  - tpep_pickup_datetime, tpep_dropoff_datetime: To calculate the trip duration \n",
    "  - Trip_distance: The elapsed trip distance in miles reported by the taximeter.\n",
    "  - Fare_amount: The time-and-distance fare calculated by the meter.\n",
    "  - Tip_amount: Tip amount – This field is automatically populated for credit card tips. Cash tips are not included.\n",
    "  - Tolls_amount: Total amount of all tolls paid in trip. \n",
    "  - Total_amount: The total amount charged to passengers. Does not include cash tips.\n",
    "\n",
    "### What are the data columns most irrelevant to your deliverable?\n",
    "\n",
    "  - Store_and_fwd_flag: dont have correlation in all dataset  \n",
    "\n",
    "\n",
    "### Are in your dataset missing or incomplete data?\n",
    "  No, but i have incositent data. The columns  with are: \n",
    "  - Fare_amount: values 0 or negative \n",
    "  - Extra: negative values, wrong values (upper then one)\n",
    "  - Mta_tax: negative values\n",
    "  - Improvement_surcharge: values 0 or negative\n",
    "  - Total_amount: values 0 or negative\n",
    "  \n",
    "### Which EDA practices will be required to begin this project?\n",
    "  - Data cleaning & Validity checks\n",
    "  - Temporal Analysis\n",
    "  - Univariate Analysis (Distribution of Target)\n",
    "  - Bivariate Analysis (Feature Relationships)\n",
    "  \n",
    "\n",
    "## **Pace: Analyze**\n",
    "\n",
    "In this stage i start data cleaning and validade checks and witch steps is i've do to achive the best resoults. We can continue with some questions. \n",
    "\n",
    "\n",
    "### What steps need to be taken to perform EDA in the most effective way to achieve the project goal?\n",
    "  #### First: I start plotting my data with Ydata to start my analisys (this is valid for Plan fase too)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "56be1928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T10:33:02.647308Z",
     "start_time": "2025-12-09T10:33:01.815402Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "df_taxi = pd.read_csv(\"2017_Yellow_Taxi_Trip_Data.csv\")\n",
    "df_taxi.drop(\"ID\", axis=1, inplace=True)\n",
    "df_taxi.drop(\"VendorID\", axis=1, inplace=True)\n",
    "profile_taxi = ProfileReport(df_taxi, title=\"Taxi analysis with ydata\", explorative=True)\n",
    "profile_taxi.to_file(\"taxi_analysis_report.html\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "1449505f",
   "metadata": {},
   "source": [
    "#### Second: I start cleaning inconsistant data i find in my plan fase"
   ]
  },
  {
   "cell_type": "code",
   "id": "32f98db3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T10:51:37.021225Z",
     "start_time": "2025-12-09T10:51:36.994244Z"
    }
   },
   "source": [
    "df_taxi.drop(columns=['store_and_fwd_flag'], errors='ignore', inplace=True)\n",
    "df_taxi['tpep_pickup_datetime'] = pd.to_datetime(df_taxi['tpep_pickup_datetime'])\n",
    "df_taxi['tpep_dropoff_datetime'] = pd.to_datetime(df_taxi['tpep_dropoff_datetime'])\n",
    "df_taxi = df_taxi[df_taxi['fare_amount'] > 0]\n",
    "df_taxi = df_taxi[df_taxi['extra'] > 0]\n",
    "df_taxi = df_taxi[df_taxi['extra'] <= 1]\n",
    "df_taxi = df_taxi[df_taxi['mta_tax'] > 0]\n",
    "df_taxi = df_taxi[df_taxi['improvement_surcharge'] > 0]\n",
    "df_taxi = df_taxi[df_taxi['total_amount'] > 0]\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "7859f0d9",
   "metadata": {},
   "source": [
    "#### Third: Now i add a new columns to help analize data\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3b1d25d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:34:53.795221Z",
     "start_time": "2025-12-09T11:34:53.786060Z"
    }
   },
   "source": [
    "df_taxi['duration'] = df_taxi['tpep_dropoff_datetime'] - df_taxi['tpep_pickup_datetime']\n",
    "df_taxi['duration_minutes'] = df_taxi['duration'].dt.total_seconds() / 60\n",
    "df_taxi = df_taxi[df_taxi['duration_minutes'] > 0]\n",
    "df_taxi.drop(columns=['duration'], inplace=True)"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "id": "29241eec",
   "metadata": {},
   "source": [
    "#### Then i get anoter report with ydata and print some graphs to identify outliers and reanilyze the dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9958ce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:35:14.556844Z",
     "start_time": "2025-12-09T11:34:55.943226Z"
    }
   },
   "source": [
    "profile_taxi = ProfileReport(df_taxi, title=\"Taxi analysis with ydata\", explorative=True)\n",
    "profile_taxi.to_file(\"taxi_analysis_report_cleaned.html\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:  33%|███▎      | 7/21 [00:00<00:01,  7.97it/s, Describe variable: duration_minutes]     \n",
      "100%|██████████| 16/16 [00:00<00:00, 366.95it/s]00:00, 22.60it/s, Describe variable: duration_minutes]\n",
      "Summarize dataset: 100%|██████████| 106/106 [00:12<00:00,  8.79it/s, Completed]                                \n",
      "Generate report structure: 100%|██████████| 1/1 [00:03<00:00,  3.60s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 11.82it/s]\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:35:15.568406Z",
     "start_time": "2025-12-09T11:35:14.583182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define columns to check for outliers\n",
    "cols_to_check = ['trip_distance', 'fare_amount', 'total_amount', 'duration_minutes']\n",
    "\n",
    "# 1. Visualization: Boxplots\n",
    "plt.figure(figsize=(10, 15))\n",
    "for i, col in enumerate(cols_to_check):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.boxplot(y=df_taxi[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outlier_boxplots.png')\n",
    "\n",
    "# 2. Statistical Identification: IQR Method\n",
    "outlier_stats = {}\n",
    "for col in cols_to_check:\n",
    "    Q1 = df_taxi[col].quantile(0.25)\n",
    "    Q3 = df_taxi[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df_taxi[(df_taxi[col] < lower_bound) | (df_taxi[col] > upper_bound)]\n",
    "    outlier_stats[col] = {\n",
    "        'IQR': IQR,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound,\n",
    "        'Num Outliers': len(outliers),\n",
    "        'Percentage': (len(outliers) / len(df_taxi)) * 100\n",
    "    }\n",
    "\n",
    "# Print stats\n",
    "print(\"Outlier Statistics (IQR Method):\")\n",
    "for col, stats in outlier_stats.items():\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  IQR: {stats['IQR']:.2f}\")\n",
    "    print(f\"  Bounds: {stats['Lower Bound']:.2f} to {stats['Upper Bound']:.2f}\")\n",
    "    print(f\"  Outliers: {stats['Num Outliers']} ({stats['Percentage']:.2f}%)\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.boxplot(y=df_taxi['total_amount'])\n",
    "plt.title(f'Boxplot of total_amount')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outlier_boxplots_fixed.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='trip_distance', y='total_amount', data=df_taxi, alpha=0.5)\n",
    "plt.title('Trip Distance vs Total Amount (Outlier Detection)')\n",
    "plt.xlabel('Trip Distance (miles)')\n",
    "plt.ylabel('Total Amount ($)')\n",
    "plt.savefig('scatter_outliers_fixed.png')"
   ],
   "id": "25d4d60f48a051e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Statistics (IQR Method):\n",
      "\n",
      "trip_distance:\n",
      "  IQR: 2.20\n",
      "  Bounds: -2.30 to 6.50\n",
      "  Outliers: 987 (9.28%)\n",
      "\n",
      "fare_amount:\n",
      "  IQR: 7.75\n",
      "  Bounds: -5.12 to 25.88\n",
      "  Outliers: 800 (7.52%)\n",
      "\n",
      "total_amount:\n",
      "  IQR: 9.00\n",
      "  Bounds: -4.70 to 31.30\n",
      "  Outliers: 793 (7.45%)\n",
      "\n",
      "duration_minutes:\n",
      "  IQR: 10.77\n",
      "  Bounds: -9.60 to 33.47\n",
      "  Outliers: 453 (4.26%)\n"
     ]
    }
   ],
   "execution_count": 66
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
